#!/bin/bash
# SoluciÃ³n para instalar tokenizers: instalar Rust primero

set -e

echo "ğŸ”§ Instalando Rust y dependencias de compilaciÃ³n..."

# Instalar Rust (necesario para compilar tokenizers)
echo "ğŸ“¦ Instalando Rust..."
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y

# Cargar Rust en el PATH
source $HOME/.cargo/env

# Instalar dependencias de compilaciÃ³n
echo "ğŸ“¦ Instalando dependencias de compilaciÃ³n..."
apt-get update -qq
apt-get install -y -qq build-essential python3-dev

# Ir al backend y activar venv
cd /opt/osac-knowledge-bot/backend
source venv/bin/activate

# Actualizar pip
pip install --upgrade pip setuptools wheel

# Instalar tokenizers (ahora deberÃ­a compilar correctamente)
echo "ğŸ“¦ Instalando tokenizers..."
pip install tokenizers

# Instalar resto de dependencias
echo "ğŸ“¦ Instalando resto de dependencias..."
pip install -r requirements.txt

echo "âœ… InstalaciÃ³n completada!"

